{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "202b4b5b",
   "metadata": {},
   "source": [
    "## Data Tokenization and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e027a40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df2f8b25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset online_news_popularity_data (/home/leeparkuky/.cache/huggingface/datasets/online_news_popularity_data/online_news_popularity_data/1.0.0/63eb244b62e86df6ad3ae3034fcbddd6ed2840885e607a97d5e8f49afab926e0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17bcf028473146bb990347ff54357d6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "articles = datasets.load_dataset('online_news_popularity_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9f96a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "ckpt = 'bert-base-uncased'\n",
    "tokenizer = AutoTokenizer.from_pretrained(ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4a058de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatenate_fernandes_variables(examples):\n",
    "    fernandes = [val for key, val in examples.items() if key not in ['title','content','shares','shares_class']]\n",
    "    fernandes = np.array(fernandes).T.tolist()\n",
    "    return {'fernandes': fernandes}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bcad2722",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/leeparkuky/.cache/huggingface/datasets/online_news_popularity_data/online_news_popularity_data/1.0.0/63eb244b62e86df6ad3ae3034fcbddd6ed2840885e607a97d5e8f49afab926e0/cache-d040c91994313900_*_of_00016.arrow\n"
     ]
    }
   ],
   "source": [
    "articles_concat = articles.map(concatenate_fernandes_variables, batched = True, batch_size = 64, num_proc = 16,\n",
    "                              remove_columns = [x for x in articles.column_names['train'] if x not in ['title','content','shares','shares_class']] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f187cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(examples):\n",
    "    text = [title + content for title, content in zip(examples['title'], examples['content'])]\n",
    "    inputs = tokenizer(text, max_length = 1500, truncation = True, padding = False)\n",
    "    N = len(inputs['input_ids'])\n",
    "    fernandes_list = []\n",
    "    for i, input_ids in enumerate(inputs['input_ids']):\n",
    "        fernandes_list.append([examples['fernandes'][i] for _ in range(len(input_ids))])\n",
    "    inputs.update({'fernandes':fernandes_list})\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ab78c39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/leeparkuky/.cache/huggingface/datasets/online_news_popularity_data/online_news_popularity_data/1.0.0/63eb244b62e86df6ad3ae3034fcbddd6ed2840885e607a97d5e8f49afab926e0/cache-fc1b51a92fbd27c3_*_of_00016.arrow\n"
     ]
    }
   ],
   "source": [
    "articles_tokenized = articles_concat.map(tokenize, batched = True, batch_size = 64, num_proc = 16,\n",
    "                   remove_columns = ['shares','shares_class','title','content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "544e2da6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['fernandes', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 39608\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles_tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4922ddb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def split_inputs_by_512(examples):\n",
    "    result = defaultdict(list)\n",
    "    for key, vec in examples.items():\n",
    "        vec = [np.array(v) for v in vec]\n",
    "        vec = np.concatenate(vec)\n",
    "        size = 512\n",
    "        remaining = 512\n",
    "        idx = 0\n",
    "        while remaining >= 512:\n",
    "            result[key].append(vec[idx*size:(idx+1)*size].tolist())\n",
    "            remaining = vec[(idx+1)*size:].shape[0]\n",
    "            idx += 1\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "060005ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=16):   0%|          | 0/39608 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "articles_tokenized = articles_tokenized.shuffle().map(split_inputs_by_512, batched = True, batch_size = 128, num_proc = 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0fceaf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['fernandes', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 41672\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles_tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6515f4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_tokenized.set_format('pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a93335c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_tokenized = articles_tokenized['train'].train_test_split(.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e4c49d",
   "metadata": {},
   "source": [
    "# Tesing if \"MashableBertForMaskedLM\" works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50dba25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from Transformer_Models import MashableBertForMaskedLM\n",
    "\n",
    "# model_ckpt = 'bert-base-uncased'\n",
    "# model = MashableBertForMaskedLM(model_ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a756d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model(**{k:v for k,v in articles_tokenized['train'][:3].items()})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ac0b5b",
   "metadata": {},
   "source": [
    "# Organizing Training Job for MaskedLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "de08d174",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm_probability=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8c635f94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from Transformer_Models import MashableBertForMaskedLM\n",
    "\n",
    "model_ckpt = 'bert-base-uncased'\n",
    "model = MashableBertForMaskedLM(model_ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "be72e94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pynvml import *\n",
    "\n",
    "\n",
    "def print_gpu_utilization():\n",
    "    nvmlInit()\n",
    "    handle = nvmlDeviceGetHandleByIndex(0)\n",
    "    info = nvmlDeviceGetMemoryInfo(handle)\n",
    "    print(f\"GPU memory occupied: {info.used//1024**2} MB.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "896abdfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory occupied: 997 MB.\n"
     ]
    }
   ],
   "source": [
    "print_gpu_utilization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7f744a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "import torch\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"pretraining-mashablebert\",\n",
    "    overwrite_output_dir = True,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    per_device_train_batch_size = 8,\n",
    "    per_device_eval_batch_size = 4,\n",
    "    fp16 = True,\n",
    "    learning_rate=2e-5,\n",
    "    num_train_epochs=30,\n",
    "    weight_decay=0.01,\n",
    "    push_to_hub=False,\n",
    "    gradient_accumulation_steps=4,\n",
    "    gradient_checkpointing=True,\n",
    "    optim = 'adafactor',\n",
    "    save_total_limit = 10\n",
    ")\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model.to(torch.device('cuda')),\n",
    "    args=training_args,\n",
    "    train_dataset=articles_tokenized[\"train\"],\n",
    "    eval_dataset=articles_tokenized[\"train\"].shuffle().select(range(64)),\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2676c9a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory occupied: 2030 MB.\n"
     ]
    }
   ],
   "source": [
    "print_gpu_utilization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6f0343f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='60500' max='37110' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [60500/37110 : < :, Epoch 46/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=60500, training_loss=0.0, metrics={'train_runtime': 0.1021, 'train_samples_per_second': 11633957.467, 'train_steps_per_second': 363524.436, 'total_flos': 6.526637265340846e+17, 'train_loss': 0.0, 'epoch': 46.93})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train(resume_from_checkpoint = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9af71e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e001ebe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e867f85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "223d20a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model('MashableBertForMaskedLM_Pretrained')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "796885c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Transformer_Models import MashableBertModel\n",
    "\n",
    "bertmodel = MashableBertModel('MashableBertForMaskedLM_Pretrained')\n",
    "# bertmodel.load_state_dict(torch.load('sample_weight.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7720c94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = torch.load('MashableBertForMaskedLM_Pretrained/pytorch_model.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6c66e8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename keys, drop unused keys for basemodel, then save the weights\n",
    "for key in [key for key in weights.keys() if key[5:] not in bertmodel.state_dict().keys()]:\n",
    "    del weights[key]\n",
    "for key in [key for key in weights.keys() if key[5:] in bertmodel.state_dict().keys()]:\n",
    "    weights[key[5:]] = weights[key]\n",
    "    del weights[key]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4923a301",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bertmodel.load_state_dict(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4c42bd29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finally save the basemodel weight in Model Weights folder\n",
    "torch.save(bertmodel.state_dict(), 'Model Weights/MashableBertModel_Pretrained.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
