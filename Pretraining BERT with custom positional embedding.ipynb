{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "202b4b5b",
   "metadata": {},
   "source": [
    "## Data Tokenization and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e027a40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df2f8b25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset online_news_popularity_data (/home/leeparkuky/.cache/huggingface/datasets/online_news_popularity_data/online_news_popularity_data/1.0.0/63eb244b62e86df6ad3ae3034fcbddd6ed2840885e607a97d5e8f49afab926e0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7153f1fca2e04dc4bf76a607cc13809b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "articles = datasets.load_dataset('online_news_popularity_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9f96a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "ckpt = 'bert-base-uncased'\n",
    "tokenizer = AutoTokenizer.from_pretrained(ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4a058de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatenate_fernandes_variables(examples):\n",
    "    fernandes = [val for key, val in examples.items() if key not in ['title','content','shares','shares_class']]\n",
    "    fernandes = np.array(fernandes).T.tolist()\n",
    "    return {'fernandes': fernandes}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bcad2722",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/leeparkuky/.cache/huggingface/datasets/online_news_popularity_data/online_news_popularity_data/1.0.0/63eb244b62e86df6ad3ae3034fcbddd6ed2840885e607a97d5e8f49afab926e0/cache-d040c91994313900_*_of_00016.arrow\n"
     ]
    }
   ],
   "source": [
    "articles_concat = articles.map(concatenate_fernandes_variables, batched = True, batch_size = 64, num_proc = 16,\n",
    "                              remove_columns = [x for x in articles.column_names['train'] if x not in ['title','content','shares','shares_class']] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f187cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(examples):\n",
    "    text = [title + content for title, content in zip(examples['title'], examples['content'])]\n",
    "    return tokenizer(text, max_length = 512, truncation = True, padding = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ab78c39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/leeparkuky/.cache/huggingface/datasets/online_news_popularity_data/online_news_popularity_data/1.0.0/63eb244b62e86df6ad3ae3034fcbddd6ed2840885e607a97d5e8f49afab926e0/cache-5d17139988fb0a89_*_of_00016.arrow\n"
     ]
    }
   ],
   "source": [
    "articles_tokenized = articles_concat.map(tokenize, batched = True, batch_size = 64, num_proc = 16,\n",
    "                   remove_columns = ['shares','shares_class','title','content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6515f4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_tokenized.set_format('pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e4c49d",
   "metadata": {},
   "source": [
    "# Tesing if \"MashableBertForMaskedLM\" works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e50dba25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Transformer_Models import MashableBertForMaskedLM\n",
    "\n",
    "model_ckpt = 'bert-base-uncased'\n",
    "model = MashableBertForMaskedLM(model_ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a756d52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MaskedLMOutput(loss=None, logits=tensor([[[ 0.0000, -0.1032,  0.2310,  ..., -0.2509,  0.3616, -0.3281],\n",
       "         [ 0.0000, -0.1271,  0.6196,  ...,  0.4624, -0.5777, -0.2988],\n",
       "         [ 0.0000, -0.1600,  0.7666,  ..., -0.0365,  0.0541,  0.2170],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0435,  0.6025,  ..., -0.1321,  0.3602, -0.1723],\n",
       "         [ 0.0000, -1.0553,  1.2979,  ...,  0.0959, -0.4221, -0.0721],\n",
       "         [ 0.0000, -0.9967,  0.8056,  ...,  0.5052, -0.7550,  0.2571]],\n",
       "\n",
       "        [[ 0.0000, -0.4462,  0.0446,  ..., -0.1923, -0.0159,  0.3493],\n",
       "         [ 0.0000, -0.4520,  0.7410,  ...,  0.0731,  0.1499,  0.2078],\n",
       "         [ 0.0000,  0.6072,  0.7652,  ..., -0.3357, -0.5743, -0.6377],\n",
       "         ...,\n",
       "         [ 0.0000,  0.3018,  0.8404,  ...,  0.4595, -0.0907,  0.0118],\n",
       "         [ 0.0000, -0.5260,  0.8660,  ...,  0.5451, -0.1357,  0.0369],\n",
       "         [ 0.0000, -0.4300,  0.7983,  ...,  0.5482, -0.3280,  0.1211]],\n",
       "\n",
       "        [[ 0.0000, -0.2728,  0.1408,  ..., -0.1378,  0.0690, -0.1533],\n",
       "         [ 0.0000,  0.0375,  0.6777,  ..., -0.2071, -0.8297, -0.4305],\n",
       "         [ 0.0000, -0.6343,  1.2457,  ...,  0.0773, -0.6226, -0.1380],\n",
       "         ...,\n",
       "         [ 0.0000,  0.1064,  0.9170,  ...,  0.1964, -0.2884, -0.3993],\n",
       "         [ 0.0000, -0.0839,  0.6026,  ...,  0.0822, -0.2813,  0.2141],\n",
       "         [ 0.0000, -0.1980,  1.1292,  ...,  0.2331, -0.1993, -0.1333]]],\n",
       "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(**{k:v for k,v in articles_tokenized['train'][:3].items()})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ac0b5b",
   "metadata": {},
   "source": [
    "# Organizing Training Job for MaskedLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de08d174",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm_probability=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c635f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Transformer_Models import MashableBertForMaskedLM\n",
    "\n",
    "model_ckpt = 'bert-base-uncased'\n",
    "model = MashableBertForMaskedLM(model_ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be72e94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pynvml import *\n",
    "\n",
    "\n",
    "def print_gpu_utilization():\n",
    "    nvmlInit()\n",
    "    handle = nvmlDeviceGetHandleByIndex(0)\n",
    "    info = nvmlDeviceGetMemoryInfo(handle)\n",
    "    print(f\"GPU memory occupied: {info.used//1024**2} MB.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "896abdfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory occupied: 880 MB.\n"
     ]
    }
   ],
   "source": [
    "print_gpu_utilization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7f744a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "import torch\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"pretraining-mashablebert\",\n",
    "    overwrite_output_dir = True,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    per_device_train_batch_size = 8,\n",
    "    per_device_eval_batch_size = 4,\n",
    "    fp16 = True,\n",
    "    learning_rate=2e-5,\n",
    "    num_train_epochs=10,\n",
    "    weight_decay=0.01,\n",
    "    push_to_hub=False,\n",
    "    gradient_accumulation_steps=4,\n",
    "    gradient_checkpointing=True,\n",
    "    optim = 'adafactor'\n",
    ")\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model.to(torch.device('cuda')),\n",
    "    args=training_args,\n",
    "    train_dataset=articles_tokenized[\"train\"],\n",
    "    eval_dataset=articles_tokenized[\"train\"].shuffle().select(range(64)),\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2676c9a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory occupied: 1908 MB.\n"
     ]
    }
   ],
   "source": [
    "print_gpu_utilization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6f0343f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='12370' max='12370' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [12370/12370 59:12, Epoch 9/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>6.407500</td>\n",
       "      <td>6.452059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>6.398100</td>\n",
       "      <td>6.355864</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=12370, training_loss=1.2272211270652285, metrics={'train_runtime': 3554.9628, 'train_samples_per_second': 111.416, 'train_steps_per_second': 3.48, 'total_flos': 1.3346207328043008e+17, 'train_loss': 1.2272211270652285, 'epoch': 10.0})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train(resume_from_checkpoint = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d35a5a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.eval_dataset = articles_tokenized['train'].train_test_split(.2)['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "458f241a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3962' max='1981' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1981/1981 13:19]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 6.367098331451416,\n",
       " 'eval_runtime': 95.5804,\n",
       " 'eval_samples_per_second': 82.883,\n",
       " 'eval_steps_per_second': 20.726,\n",
       " 'epoch': 10.0}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b34b32e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.args.num_train_epochs = 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cec1fba7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16081' max='16081' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16081/16081 1:47:36, Epoch 12/13]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>6.398100</td>\n",
       "      <td>6.366686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>6.399100</td>\n",
       "      <td>6.372880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>6.398200</td>\n",
       "      <td>6.375506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>6.391100</td>\n",
       "      <td>6.371051</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=16081, training_loss=1.6235503040211954, metrics={'train_runtime': 6458.4946, 'train_samples_per_second': 79.725, 'train_steps_per_second': 2.49, 'total_flos': 1.735006952645591e+17, 'train_loss': 1.6235503040211954, 'epoch': 13.0})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train(resume_from_checkpoint = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3c7873d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<transformers.trainer.Trainer at 0x7f159fce64d0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "223d20a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model('MashableBertForMaskedLM_Pretrained')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "796885c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Transformer_Models import MashableBertModel\n",
    "\n",
    "bertmodel = MashableBertModel('MashableBertForMaskedLM_Pretrained')\n",
    "# bertmodel.load_state_dict(torch.load('sample_weight.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7720c94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = torch.load('MashableBertForMaskedLM_Pretrained/pytorch_model.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6c66e8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename keys, drop unused keys for basemodel, then save the weights\n",
    "for key in [key for key in weights.keys() if key[5:] not in bertmodel.state_dict().keys()]:\n",
    "    del weights[key]\n",
    "for key in [key for key in weights.keys() if key[5:] in bertmodel.state_dict().keys()]:\n",
    "    weights[key[5:]] = weights[key]\n",
    "    del weights[key]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4923a301",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bertmodel.load_state_dict(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4c42bd29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finally save the basemodel weight in Model Weights folder\n",
    "torch.save(bertmodel.state_dict(), 'Model Weights/MashableBertModel_Pretrained.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
